{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第6章: 英語テキストの処理\n",
    "英語のテキスト[nlp.txt](http://www.cl.ecei.tohoku.ac.jp/nlp100/data/nlp.txt)に対して，以下の処理を実行せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 data/nlp.txt\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/nlp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing\n",
      "From Wikipedia, the free encyclopedia\n",
      "\n",
      "Natural language processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human (natural) languages. As such, NLP is related to the area of humani-computer interaction. Many challenges in NLP involve natural language understanding, that is, enabling computers to derive meaning from human or natural language input, and others involve natural language generation.\n",
      "\n",
      "History\n",
      "\n",
      "The history of NLP generally starts in the 1950s, although work can be found from earlier periods. In 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence.\n",
      "\n",
      "The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English. The authors claimed that within three or five years, machine translation would be a solved problem. However, real progress was much slower, and after the ALPAC report in 1966, which found that ten year long research had failed to fulfill the expectations, funding for machine translation was dramatically reduced. Little further research in machine translation was conducted until the late 1980s, when the first statistical machine translation systems were developed.\n"
     ]
    }
   ],
   "source": [
    "!head data/nlp.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_path = 'data/nlp.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 50. 文区切り\n",
    "(. or ; or : or ? or !) → 空白文字 → 英大文字というパターンを文の区切りと見なし，入力された文書を1行1文の形式で出力せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パターン1\n",
    "- 正規表現, finditer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[正規表現解析ツール](https://regexper.com/#%28.%2B%3F%29%28%24%7C%5B.%3B%3A%3F!%5D%5Cs%2B%28%3F%3D%5BA-Z%5D%29%29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2sent(f):\n",
    "    for line in f:\n",
    "        for sentence in re.finditer(r\"(.+?)($|[.;:?!]\\s+(?=[A-Z]))\",line):\n",
    "            yield sentence.group().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626 µs ± 47.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with open(infile_path) as f:\n",
    "    for line in text2sent(f):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パターン2\n",
    "- 正規表現, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2sent(f):\n",
    "    for line in f:\n",
    "        for sentence in re.split(r\"(?<=[.;:?!])\\s+(?=[A-Z])\",line.strip()):\n",
    "            if sentence: yield sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399 µs ± 27 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with open(infile_path) as f:\n",
    "    for line in text2sent(f):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- splitの方が1.6倍くらい早い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing\n",
      "From Wikipedia, the free encyclopedia\n",
      "Natural language processing (NLP) is a field of computer science, artificial intelligence, and linguistics concerned with the interactions between computers and human (natural) languages.\n",
      "As such, NLP is related to the area of humani-computer interaction.\n",
      "Many challenges in NLP involve natural language understanding, that is, enabling computers to derive meaning from human or natural language input, and others involve natural language generation.\n"
     ]
    }
   ],
   "source": [
    "with open(infile_path) as f:\n",
    "    for sent in islice(text2sent(f),5):\n",
    "        print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memo\n",
    "# 関数にファイルポインタを渡すのは気持ち悪いかも\n",
    "# open with で ファイルを開いて閉じるので、関数内で完結させた方がいいかも？\n",
    "\n",
    "# Rule-base\n",
    "# nltk\n",
    "# spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# assert\n",
    "a = 3\n",
    "assert a == 3\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "コメント",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-14b89f3e6746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# assert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"コメント\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: コメント"
     ]
    }
   ],
   "source": [
    "# assert\n",
    "a = 3\n",
    "assert a == 2, \"コメント\"\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ワンライナーシリーズ\n",
    "# grep\n",
    "# sed\n",
    "# perl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 51. 単語の切り出し\n",
    "空白を単語の区切りとみなし，50の出力を入力として受け取り，1行1単語の形式で出力せよ．ただし，文の終端では空行を出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 句読点等の除去\n",
    "# re.sub(r'^\\w\\s','',sentence)\n",
    "# strip(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2word(sentence):\n",
    "    for word in sentence.split():\n",
    "        yield word.strip(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\n",
      "language\n",
      "processing\n",
      "\n",
      "From\n",
      "Wikipedia\n",
      "the\n",
      "free\n",
      "encyclopedia\n",
      "\n",
      "Natural\n",
      "language\n",
      "processing\n",
      "NLP\n",
      "is\n",
      "a\n",
      "field\n",
      "of\n",
      "computer\n",
      "science\n",
      "artificial\n",
      "intelligence\n",
      "and\n",
      "linguistics\n",
      "concerned\n",
      "with\n",
      "the\n",
      "interactions\n",
      "between\n",
      "computers\n",
      "and\n",
      "human\n",
      "natural\n",
      "languages\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(infile_path) as f:\n",
    "    for sent in islice(text2sent(f),3):\n",
    "        for word in sent2word(sent):\n",
    "            print(word)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memo\n",
    "# sed G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 52. ステミング\n",
    "51の出力を入力として受け取り，Porterのステミングアルゴリズムを適用し，単語と語幹をタブ区切り形式で出力せよ． Pythonでは，Porterのステミングアルゴリズムの実装として[stemming](https://pypi.org/project/stemming/)モジュールを利用するとよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\tnatur\n",
      "language\tlanguag\n",
      "processing\tprocess\n",
      "\n",
      "From\tfrom\n",
      "Wikipedia\twikipedia\n",
      "the\tthe\n",
      "free\tfree\n",
      "encyclopedia\tencyclopedia\n",
      "\n",
      "Natural\tnatur\n",
      "language\tlanguag\n",
      "processing\tprocess\n",
      "NLP\tnlp\n",
      "is\tis\n",
      "a\ta\n",
      "field\tfield\n",
      "of\tof\n",
      "computer\tcomput\n",
      "science\tscienc\n",
      "artificial\tartifici\n",
      "intelligence\tintellig\n",
      "and\tand\n",
      "linguistics\tlinguist\n",
      "concerned\tconcern\n",
      "with\twith\n",
      "the\tthe\n",
      "interactions\tinteract\n",
      "between\tbetween\n",
      "computers\tcomput\n",
      "and\tand\n",
      "human\thuman\n",
      "natural\tnatur\n",
      "languages\tlanguag\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stemmer = stem.PorterStemmer()\n",
    "with open(infile_path) as f:\n",
    "    for sent in islice(text2sent(f),3):\n",
    "        for word in sent2word(sent):\n",
    "            print(word, stemmer.stem(word), sep='\\t')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 色々なstemer\n",
    "# nltk\n",
    "# stemming porter2\n",
    "# snowballstemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 53. Tokenization\n",
    "[Stanford Core NLP](https://stanfordnlp.github.io/CoreNLP/)を用い，入力テキストの解析結果をXML形式で得よ．また，このXMLファイルを読み込み，入力テキストを1行1単語の形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java -mx5g -cp \"/Users/konnoryuto/Documents/lab/stanford-corenlp/stanford-corenlp-full-2018-02-27/*\" edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators tokenize,ssplit,pos,lemma,ner,parse,depparse,dcoref -file data/nlp.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [1.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [2.0 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "[main] INFO edu.stanford.nlp.time.JollyDayHolidays - Initializing JollyDayHoliday for SUTime from classpath edu/stanford/nlp/models/sutime/jollyday/Holidays_sutime.xml as sutime.binder.1.\n",
      "[main] INFO edu.stanford.nlp.time.TimeExpressionExtractorImpl - Using following SUTime rules: edu/stanford/nlp/models/sutime/defs.sutime.txt,edu/stanford/nlp/models/sutime/english.sutime.txt,edu/stanford/nlp/models/sutime/english.holidays.sutime.txt\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - TokensRegexNERAnnotator ner.fine.regexner: Read 580641 unique entries out of 581790 from edu/stanford/nlp/models/kbp/regexner_caseless.tab, 0 TokensRegex patterns.\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - TokensRegexNERAnnotator ner.fine.regexner: Read 4857 unique entries out of 4868 from edu/stanford/nlp/models/kbp/regexner_cased.tab, 0 TokensRegex patterns.\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokensRegexNERAnnotator - TokensRegexNERAnnotator ner.fine.regexner: Read 585498 unique entries from 2 files\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... done [0.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 99996, Elapsed Time: 25.922 (s)\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [28.5 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator dcoref\n",
      "[main] INFO edu.stanford.nlp.pipeline.CorefMentionAnnotator - Using mention detector type: dependency\n",
      "\n",
      "Processing file /Users/konnoryuto/Documents/lab/100knock-2018/ryuto/chapter06/data/nlp.txt ... writing to /Users/konnoryuto/Documents/lab/100knock-2018/ryuto/chapter06/nlp.txt.xml\n",
      "Annotating file /Users/konnoryuto/Documents/lab/100knock-2018/ryuto/chapter06/data/nlp.txt ... done [20.5 sec].\n",
      "\n",
      "Annotation pipeline timing information:\n",
      "TokenizerAnnotator: 0.1 sec.\n",
      "WordsToSentencesAnnotator: 0.0 sec.\n",
      "POSTaggerAnnotator: 0.3 sec.\n",
      "MorphaAnnotator: 0.1 sec.\n",
      "NERCombinerAnnotator: 4.8 sec.\n",
      "ParserAnnotator: 10.3 sec.\n",
      "DependencyParseAnnotator: 1.4 sec.\n",
      "DeterministicCorefAnnotator: 3.4 sec.\n",
      "TOTAL: 20.5 sec. for 1452 tokens at 70.9 tokens/sec.\n",
      "Pipeline setup: 75.3 sec.\n",
      "Total time for StanfordCoreNLP pipeline: 96.0 sec.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "~/Documents/lab/stanford-corenlp/stanford-corenlp-full-2018-02-27/corenlp.sh -annotators tokenize,ssplit,pos,lemma,ner,parse,depparse,dcoref -file data/nlp.txt\n",
    "mv nlp.txt.xml work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xmlファイルの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<?xml-stylesheet href=\"CoreNLP-to-HTML.xsl\" type=\"text/xsl\"?>\n",
      "<root>\n",
      "  <document>\n",
      "    <docId>nlp.txt</docId>\n",
      "    <sentences>\n",
      "      <sentence id=\"1\">\n",
      "        <tokens>\n",
      "          <token id=\"1\">\n",
      "            <word>Natural</word>\n",
      "            <lemma>natural</lemma>\n",
      "            <CharacterOffsetBegin>0</CharacterOffsetBegin>\n",
      "            <CharacterOffsetEnd>7</CharacterOffsetEnd>\n",
      "            <POS>JJ</POS>\n",
      "            <NER>O</NER>\n",
      "            <Speaker>PER0</Speaker>\n",
      "          </token>\n",
      "          <token id=\"2\">\n",
      "            <word>language</word>\n",
      "            <lemma>language</lemma>\n"
     ]
    }
   ],
   "source": [
    "! head -n 20 work/nlp.txt.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xmlの解析 [xml.etree.ElementTree](https://docs.python.jp/3/library/xml.etree.elementtree.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('work/nlp.txt.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\n",
      "language\n",
      "processing\n",
      "From\n",
      "Wikipedia\n",
      ",\n",
      "the\n",
      "free\n",
      "encyclopedia\n",
      "Natural\n"
     ]
    }
   ],
   "source": [
    "for word in islice(root.iter(\"word\"),10):\n",
    "    print(word.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memo\n",
    "# ifで not equal をできるだけ使わない\n",
    "# 可読性の向上\n",
    "# readlinesはメモリ消費が激しい\n",
    "# lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# corenlpの主要なオプション\n",
    "- annotators = tokenize,ssplit,pos,lemma,ner,parse,dcoref\n",
    "\n",
    "行う処理\n",
    "\n",
    "- file = work/nlp_sents.txt\n",
    "\n",
    " 入力ファイル\n",
    "    \n",
    "- outputExtension = .xml\n",
    "\n",
    " 出力ファイル形式\n",
    "    \n",
    "- outputDirectory = work\n",
    "\n",
    " 出力ディレクトリ\n",
    "    \n",
    "- ssplit.eolonly\n",
    "\n",
    " 行末のみを文区切りとして扱う　(sentence segmentation済みであればtrueに)\n",
    "    \n",
    "- tokenize.whitespace\n",
    "\n",
    " 空白のみを単語区切りとして扱う　(tokenization済みであればtrueに)\n",
    "    \n",
    "- Xmx[1-6]g\n",
    "\n",
    " corenlpのためにJavaが確保するRAMの量 (Xmx4gであれば4GB)。\n",
    "    \n",
    " corenlpサイドとしては、2GB確保すれば十分でしょと言っている。\n",
    "\n",
    " メモリ使用量はどの処理を行うかにも大きく依存し、dcorefを行う場合メモリ使用量が比較的多くなるとのこと。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 54. 品詞タグ付け\n",
    "Stanford Core NLPの解析結果XMLを読み込み，単語，レンマ，品詞をタブ区切り形式で出力せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\tnatural\tJJ\n",
      "language\tlanguage\tNN\n",
      "processing\tprocessing\tNN\n",
      "From\tfrom\tIN\n",
      "Wikipedia\tWikipedia\tNNP\n",
      ",\t,\t,\n",
      "the\tthe\tDT\n",
      "free\tfree\tJJ\n",
      "encyclopedia\tencyclopedia\tNN\n",
      "Natural\tnatural\tJJ\n"
     ]
    }
   ],
   "source": [
    "for token in islice(root.iter(\"token\"),10):\n",
    "    \n",
    "    word = token.find('word').text\n",
    "    lemma = token.find('lemma').text\n",
    "    pos = token.find('POS').text\n",
    "    \n",
    "    print(word, lemma, pos, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 複数人で作業するとき、前処理をするときは何を使ったのかを明記しておく"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 55. 固有表現抽出\n",
    "入力文中の人名をすべて抜き出せ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alan Turing\n",
      "Joseph Weizenbaum\n",
      "MARGIE\n",
      "Schank\n",
      "Wilensky\n",
      "Meehan\n",
      "Lehnert\n",
      "Carbonell\n",
      "Lehnert\n",
      "Racter\n",
      "Jabberwacky\n",
      "Moore\n"
     ]
    }
   ],
   "source": [
    "# PERSONでgroupby\n",
    "for is_person, token_g in groupby(root.iter(\"token\"), key=lambda token: token.find(\"NER\").text == 'PERSON'):\n",
    "    if is_person:\n",
    "        person_name = ' '.join(token.find(\"word\").text for token in token_g)\n",
    "        print(person_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 56. 共参照解析\n",
    "Stanford Core NLPの共参照解析の結果に基づき，文中の参照表現（mention）を代表参照表現（representative mention）に置換せよ．ただし，置換するときは，「代表参照表現（参照表現）」のように，元の参照表現が分かるように配慮せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coreferenceの構造を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    <coreference>\n",
      "      <coreference>\n",
      "        <mention representative=\"true\">\n",
      "          <sentence>1</sentence>\n",
      "          <start>7</start>\n",
      "          <end>16</end>\n",
      "          <head>12</head>\n",
      "          <text>the free encyclopedia Natural language processing -LRB- NLP -RRB-</text>\n",
      "        </mention>\n",
      "        <mention>\n",
      "          <sentence>1</sentence>\n",
      "          <start>17</start>\n",
      "          <end>22</end>\n",
      "          <head>18</head>\n",
      "          <text>a field of computer science</text>\n",
      "        </mention>\n",
      "        <mention>\n",
      "          <sentence>18</sentence>\n",
      "          <start>23</start>\n",
      "          <end>25</end>\n"
     ]
    }
   ],
   "source": [
    "!grep -A 20 \"<coreference>\" work/nlp.txt.xml | head -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coreferenceの情報を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_dic = {}\n",
    "\n",
    "for ment in root.iter(\"mention\"):\n",
    "    if ment.get(\"representative\"):  # 代表参照表現を抽出\n",
    "        rep = ment.find(\"text\").text\n",
    "    else:\n",
    "        coref_dic[ment[0].text, ment[1].text] = rep + ' ('  # 置換の最初 (sentence, start)\n",
    "        coref_dic[ment[0].text, ment[2].text] = ')'  # 置換の最後 (sentence, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 置換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sent2word(sent):  # sentenceから置換したものをword単位で出力\n",
    "    for token in sent.iter(\"token\"):\n",
    "        ids = (sent.get(\"id\"), token.get(\"id\"))\n",
    "        word = token.find(\"word\").text\n",
    "        \n",
    "        if ids in coref_dic:  # 共参照情報が存在するとき\n",
    "            yield coref_dic[ids]\n",
    "        yield word\n",
    "        \n",
    "def replace_root2sent(root):  # rootから置換したものをsentence単位で出力\n",
    "    for sents in root.iter(\"sentences\"):\n",
    "        for sent in sents:\n",
    "            yield ' '.join(word for word in replace_sent2word(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing From Wikipedia , the free encyclopedia Natural language processing -LRB- NLP -RRB- is [the free encyclopedia Natural language processing -LRB- NLP -RRB-] ( a field of computer science ) , artificial intelligence , and linguistics concerned with the interactions between computers and human -LRB- natural -RRB- languages .\n",
      "As such , NLP is related to the area of humani-computer interaction .\n",
      "Many challenges in NLP involve natural language understanding , that is , enabling [computers] ( computers ) to derive meaning from human or natural language input , and others involve natural language generation .\n",
      "History The history of NLP generally starts in the 1950s , although work can be found from earlier periods .\n",
      "In 1950 , Alan Turing published an article titled `` Computing Machinery and Intelligence '' which proposed what is now called the [Alan Turing] ( Turing ) test as a criterion of intelligence .\n",
      "The Georgetown experiment in 1954 involved fully automatic translation of more than sixty Russian sentences into English .\n",
      "The authors claimed that within three or five years , [a solved problem] ( machine translation ) would be a solved problem .\n",
      "However , real progress was much slower , and after the ALPAC report in 1966 , which found that ten year long research had failed to fulfill the expectations , funding for machine translation was dramatically reduced .\n",
      "Little further research in [a solved problem] ( machine translation ) was conducted until the late 1980s , when the first statistical machine translation systems were developed .\n",
      "Some notably successful NLP systems developed in the 1960s were SHRDLU , [SHRDLU] ( a natural language system working in restricted `` blocks worlds '' with restricted vocabularies ) , and ELIZA , a simulation of a Rogerian psychotherapist , written by Joseph Weizenbaum between 1964 to 1966 .\n"
     ]
    }
   ],
   "source": [
    "for i in islice(replace_root2sent(root),10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 57. 係り受け解析\n",
    "Stanford Core NLPの係り受け解析の結果（collapsed-dependencies）を有向グラフとして可視化せよ．可視化には，係り受け木をDOT言語に変換し，Graphvizを用いるとよい．また，Pythonから有向グラフを直接的に可視化するには，pydotを使うとよい．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dependenciesの構造を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        <dependencies type=\"collapsed-dependencies\">\n",
      "          <dep type=\"root\">\n",
      "            <governor idx=\"0\">ROOT</governor>\n",
      "            <dependent idx=\"18\">field</dependent>\n",
      "          </dep>\n",
      "          <dep type=\"amod\">\n",
      "            <governor idx=\"3\">processing</governor>\n",
      "            <dependent idx=\"1\">Natural</dependent>\n",
      "          </dep>\n",
      "          <dep type=\"compound\">\n",
      "            <governor idx=\"3\">processing</governor>\n",
      "            <dependent idx=\"2\">language</dependent>\n",
      "          </dep>\n",
      "          <dep type=\"nsubj\">\n",
      "            <governor idx=\"18\">field</governor>\n",
      "            <dependent idx=\"3\">processing</dependent>\n",
      "          </dep>\n",
      "          <dep type=\"case\">\n",
      "            <governor idx=\"5\">Wikipedia</governor>\n",
      "            <dependent idx=\"4\">From</dependent>\n",
      "grep: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!grep -A 20 'type=\"collapsed-dependencies\"' work/nlp.txt.xml | head -n 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cd_deps(root):  # 係り受け解析の結果だけを取ってくる\n",
    "    for deps in root.iter(\"dependencies\"):\n",
    "        if deps.get(\"type\") == \"collapsed-dependencies\":\n",
    "            yield deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph = Digraph(format='png')\n",
    "\n",
    "for deps in islice(get_cd_deps(root), 1):\n",
    "    for dep in deps:\n",
    "        gove = dep.find(\"governor\")\n",
    "        depe = dep.find(\"dependent\")\n",
    "        \n",
    "        if depe.text not in string.punctuation:  # 記号は除外\n",
    "            parent = gove.get(\"idx\") + '.' + gove.text\n",
    "            child = depe.get(\"idx\") + '.' + depe.text\n",
    "            Graph.edge(parent, child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"1155pt\" height=\"764pt\"\n",
       " viewBox=\"0.00 0.00 1155.00 764.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 760)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-760 1151.0035,-760 1151.0035,4 -4,4\"/>\n",
       "<!-- 0.ROOT -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0.ROOT</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"384.2569\" cy=\"-738\" rx=\"40.6265\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"384.2569\" y=\"-733.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0.ROOT</text>\n",
       "</g>\n",
       "<!-- 18.field -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>18.field</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"384.2569\" cy=\"-666\" rx=\"36.7671\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"384.2569\" y=\"-661.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">18.field</text>\n",
       "</g>\n",
       "<!-- 0.ROOT&#45;&gt;18.field -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0.ROOT&#45;&gt;18.field</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M384.2569,-719.8314C384.2569,-712.131 384.2569,-702.9743 384.2569,-694.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"387.757,-694.4132 384.2569,-684.4133 380.757,-694.4133 387.757,-694.4132\"/>\n",
       "</g>\n",
       "<!-- 3.processing -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>3.processing</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"220.2569\" cy=\"-594\" rx=\"54.6234\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"220.2569\" y=\"-589.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">3.processing</text>\n",
       "</g>\n",
       "<!-- 18.field&#45;&gt;3.processing -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>18.field&#45;&gt;3.processing</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M356.807,-653.9488C331.0532,-642.6423 292.1611,-625.5677 262.4624,-612.5292\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"263.7347,-609.2654 253.1712,-608.4502 260.9207,-615.6749 263.7347,-609.2654\"/>\n",
       "</g>\n",
       "<!-- 16.is -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>16.is</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"348.2569\" cy=\"-594\" rx=\"27.1195\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"348.2569\" y=\"-589.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">16.is</text>\n",
       "</g>\n",
       "<!-- 18.field&#45;&gt;16.is -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>18.field&#45;&gt;16.is</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M375.358,-648.2022C371.1546,-639.7955 366.0527,-629.5917 361.4143,-620.3149\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"364.4082,-618.4762 356.8055,-611.0972 358.1472,-621.6068 364.4082,-618.4762\"/>\n",
       "</g>\n",
       "<!-- 17.a -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>17.a</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"420.2569\" cy=\"-594\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"420.2569\" y=\"-589.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">17.a</text>\n",
       "</g>\n",
       "<!-- 18.field&#45;&gt;17.a -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>18.field&#45;&gt;17.a</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M393.1557,-648.2022C397.3591,-639.7955 402.461,-629.5917 407.0994,-620.3149\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"410.3666,-621.6068 411.7083,-611.0972 404.1056,-618.4762 410.3666,-621.6068\"/>\n",
       "</g>\n",
       "<!-- 21.science -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>21.science</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"526.2569\" cy=\"-594\" rx=\"47.3647\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"526.2569\" y=\"-589.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">21.science</text>\n",
       "</g>\n",
       "<!-- 18.field&#45;&gt;21.science -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>18.field&#45;&gt;21.science</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M409.972,-652.9613C431.9414,-641.8219 463.839,-625.6485 488.6717,-613.0573\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"490.4716,-616.0689 497.8078,-608.4249 487.3059,-609.8256 490.4716,-616.0689\"/>\n",
       "</g>\n",
       "<!-- 1.Natural -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>1.Natural</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"43.2569\" cy=\"-522\" rx=\"43.0151\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"43.2569\" y=\"-517.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1.Natural</text>\n",
       "</g>\n",
       "<!-- 3.processing&#45;&gt;1.Natural -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>3.processing&#45;&gt;1.Natural</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M185.7093,-579.9468C156.5686,-568.0929 114.8077,-551.1054 84.0323,-538.5866\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"85.0379,-535.2172 74.4562,-534.6912 82.4003,-541.7013 85.0379,-535.2172\"/>\n",
       "</g>\n",
       "<!-- 2.language -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2.language</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"153.2569\" cy=\"-522\" rx=\"48.8181\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"153.2569\" y=\"-517.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2.language</text>\n",
       "</g>\n",
       "<!-- 3.processing&#45;&gt;2.language -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>3.processing&#45;&gt;2.language</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M204.038,-576.5708C195.726,-567.6385 185.4593,-556.6056 176.3374,-546.8029\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"178.7009,-544.2051 169.3263,-539.2687 173.5764,-548.9737 178.7009,-544.2051\"/>\n",
       "</g>\n",
       "<!-- 5.Wikipedia -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5.Wikipedia</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"273.2569\" cy=\"-522\" rx=\"53.447\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"273.2569\" y=\"-517.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5.Wikipedia</text>\n",
       "</g>\n",
       "<!-- 3.processing&#45;&gt;5.Wikipedia -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>3.processing&#45;&gt;5.Wikipedia</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M233.358,-576.2022C239.6478,-567.6576 247.3042,-557.2564 254.2218,-547.859\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"257.1969,-549.7213 260.3064,-539.593 251.5595,-545.5715 257.1969,-549.7213\"/>\n",
       "</g>\n",
       "<!-- 4.From -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>4.From</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"190.2569\" cy=\"-450\" rx=\"35.8065\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"190.2569\" y=\"-445.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4.From</text>\n",
       "</g>\n",
       "<!-- 5.Wikipedia&#45;&gt;4.From -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>5.Wikipedia&#45;&gt;4.From</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M253.587,-504.937C242.3403,-495.1808 228.1034,-482.8307 215.978,-472.3123\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"218.2148,-469.6193 208.3674,-465.7103 213.6278,-474.907 218.2148,-469.6193\"/>\n",
       "</g>\n",
       "<!-- 12.processing -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>12.processing</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"303.2569\" cy=\"-450\" rx=\"58.9668\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"303.2569\" y=\"-445.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">12.processing</text>\n",
       "</g>\n",
       "<!-- 5.Wikipedia&#45;&gt;12.processing -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>5.Wikipedia&#45;&gt;12.processing</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M280.8271,-503.8314C284.1924,-495.7547 288.2252,-486.0761 291.9374,-477.1668\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"295.1775,-478.4904 295.7929,-467.9134 288.716,-475.798 295.1775,-478.4904\"/>\n",
       "</g>\n",
       "<!-- 7.the -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>7.the</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"63.2569\" cy=\"-378\" rx=\"27.5867\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63.2569\" y=\"-373.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">7.the</text>\n",
       "</g>\n",
       "<!-- 12.processing&#45;&gt;7.the -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>12.processing&#45;&gt;7.the</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M258.4845,-438.1467C199.2842,-422.4656 102.1553,-396.7067 100.2569,-396 98.1899,-395.2305 96.0834,-394.3848 93.9768,-393.4925\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"95.418,-390.303 84.864,-389.3734 92.5347,-396.6817 95.418,-390.303\"/>\n",
       "</g>\n",
       "<!-- 8.free -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>8.free</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"139.2569\" cy=\"-378\" rx=\"30.4592\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"139.2569\" y=\"-373.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">8.free</text>\n",
       "</g>\n",
       "<!-- 12.processing&#45;&gt;8.free -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>12.processing&#45;&gt;8.free</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M268.997,-435.213C244.0723,-424.4229 209.5303,-409.4027 179.2569,-396 177.2201,-395.0983 175.1266,-394.1676 173.0159,-393.2264\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"174.3317,-389.9808 163.7744,-389.0894 171.4716,-396.3699 174.3317,-389.9808\"/>\n",
       "</g>\n",
       "<!-- 9.encyclopedia -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>9.encyclopedia</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"251.2569\" cy=\"-378\" rx=\"63.2759\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"251.2569\" y=\"-373.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">9.encyclopedia</text>\n",
       "</g>\n",
       "<!-- 12.processing&#45;&gt;9.encyclopedia -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>12.processing&#45;&gt;9.encyclopedia</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M290.4029,-432.2022C284.2779,-423.7214 276.8319,-413.4115 270.0849,-404.0696\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"272.8355,-401.9001 264.1431,-395.8425 267.1607,-405.9986 272.8355,-401.9001\"/>\n",
       "</g>\n",
       "<!-- 10.Natural -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>10.Natural</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"380.2569\" cy=\"-378\" rx=\"47.8579\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"380.2569\" y=\"-373.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">10.Natural</text>\n",
       "</g>\n",
       "<!-- 12.processing&#45;&gt;10.Natural -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>12.processing&#45;&gt;10.Natural</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M321.8964,-432.5708C331.7815,-423.3276 344.072,-411.8352 354.821,-401.7842\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"357.4054,-404.1594 362.3192,-394.7729 352.6244,-399.0464 357.4054,-404.1594\"/>\n",
       "</g>\n",
       "<!-- 11.language -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>11.language</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"498.2569\" cy=\"-378\" rx=\"52.5145\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"498.2569\" y=\"-373.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">11.language</text>\n",
       "</g>\n",
       "<!-- 12.processing&#45;&gt;11.language -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>12.processing&#45;&gt;11.language</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M340.8548,-436.1177C372.7862,-424.3276 418.7128,-407.3701 452.7219,-394.8129\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"454.2513,-397.9793 462.4199,-391.2321 451.8266,-391.4126 454.2513,-397.9793\"/>\n",
       "</g>\n",
       "<!-- 14.NLP -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>14.NLP</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"607.2569\" cy=\"-378\" rx=\"37.7362\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"607.2569\" y=\"-373.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">14.NLP</text>\n",
       "</g>\n",
       "<!-- 12.processing&#45;&gt;14.NLP -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>12.processing&#45;&gt;14.NLP</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M355.5437,-441.5236C407.9023,-432.4513 490.4997,-416.5452 560.2569,-396 563.0464,-395.1784 565.905,-394.2662 568.7675,-393.3009\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"570.1712,-396.5165 578.4206,-389.8684 567.8259,-389.9211 570.1712,-396.5165\"/>\n",
       "</g>\n",
       "<!-- 13.&#45;LRB&#45; -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>13.&#45;LRB&#45;</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"530.2569\" cy=\"-306\" rx=\"44.0015\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"530.2569\" y=\"-301.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">13.&#45;LRB&#45;</text>\n",
       "</g>\n",
       "<!-- 14.NLP&#45;&gt;13.&#45;LRB&#45; -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>14.NLP&#45;&gt;13.&#45;LRB&#45;</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M589.7844,-361.6621C579.6177,-352.1556 566.6292,-340.0105 555.3804,-329.4921\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"557.6215,-326.796 547.9267,-322.5225 552.8405,-331.909 557.6215,-326.796\"/>\n",
       "</g>\n",
       "<!-- 15.&#45;RRB&#45; -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>15.&#45;RRB&#45;</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"637.2569\" cy=\"-306\" rx=\"44.9946\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"637.2569\" y=\"-301.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">15.&#45;RRB&#45;</text>\n",
       "</g>\n",
       "<!-- 14.NLP&#45;&gt;15.&#45;RRB&#45; -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>14.NLP&#45;&gt;15.&#45;RRB&#45;</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M614.6726,-360.2022C618.0621,-352.0675 622.1527,-342.2501 625.916,-333.2181\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"629.207,-334.4195 629.8225,-323.8425 622.7455,-331.7271 629.207,-334.4195\"/>\n",
       "</g>\n",
       "<!-- 19.of -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>19.of</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"373.2569\" cy=\"-522\" rx=\"28.5557\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"373.2569\" y=\"-517.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">19.of</text>\n",
       "</g>\n",
       "<!-- 21.science&#45;&gt;19.of -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>21.science&#45;&gt;19.of</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M495.6607,-579.9301C472.2331,-569.1149 439.1404,-553.7474 410.2569,-540 408.6605,-539.2402 407.0269,-538.459 405.3783,-537.6678\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"406.4526,-534.2999 395.9255,-533.1038 403.409,-540.6036 406.4526,-534.2999\"/>\n",
       "</g>\n",
       "<!-- 20.computer -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>20.computer</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"474.2569\" cy=\"-522\" rx=\"54.6147\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"474.2569\" y=\"-517.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">20.computer</text>\n",
       "</g>\n",
       "<!-- 21.science&#45;&gt;20.computer -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>21.science&#45;&gt;20.computer</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M513.6691,-576.5708C507.4556,-567.9675 499.8348,-557.4156 492.956,-547.8911\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"495.6013,-545.5758 486.9089,-539.5182 489.9265,-549.6743 495.6013,-545.5758\"/>\n",
       "</g>\n",
       "<!-- 24.intelligence -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>24.intelligence</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"609.2569\" cy=\"-522\" rx=\"62.324\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"609.2569\" y=\"-517.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">24.intelligence</text>\n",
       "</g>\n",
       "<!-- 21.science&#45;&gt;24.intelligence -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>21.science&#45;&gt;24.intelligence</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M545.5074,-577.3008C556.2464,-567.985 569.8076,-556.221 581.6587,-545.9406\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"584.274,-548.3053 589.5344,-539.1086 579.687,-543.0176 584.274,-548.3053\"/>\n",
       "</g>\n",
       "<!-- 26.and -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>26.and</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"723.2569\" cy=\"-522\" rx=\"33.8597\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"723.2569\" y=\"-517.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">26.and</text>\n",
       "</g>\n",
       "<!-- 21.science&#45;&gt;26.and -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>21.science&#45;&gt;26.and</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M561.951,-582.1525C593.3038,-571.5872 640.0574,-555.4463 680.2569,-540 682.4878,-539.1428 684.7762,-538.2438 687.0792,-537.3241\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"688.5767,-540.4935 696.5184,-533.4806 685.9368,-534.0103 688.5767,-540.4935\"/>\n",
       "</g>\n",
       "<!-- 27.linguistics -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>27.linguistics</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"832.2569\" cy=\"-522\" rx=\"57.5391\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"832.2569\" y=\"-517.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">27.linguistics</text>\n",
       "</g>\n",
       "<!-- 21.science&#45;&gt;27.linguistics -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>21.science&#45;&gt;27.linguistics</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M567.5835,-585.2921C615.5135,-575.0563 696.8356,-557.2672 766.2569,-540 770.588,-538.9227 775.0697,-537.7739 779.5645,-536.5976\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"780.6034,-539.9432 789.3718,-533.9962 778.8086,-533.1772 780.6034,-539.9432\"/>\n",
       "</g>\n",
       "<!-- 23.artificial -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>23.artificial</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"609.2569\" cy=\"-450\" rx=\"50.756\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"609.2569\" y=\"-445.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">23.artificial</text>\n",
       "</g>\n",
       "<!-- 24.intelligence&#45;&gt;23.artificial -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>24.intelligence&#45;&gt;23.artificial</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M609.2569,-503.8314C609.2569,-496.131 609.2569,-486.9743 609.2569,-478.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"612.757,-478.4132 609.2569,-468.4133 605.757,-478.4133 612.757,-478.4132\"/>\n",
       "</g>\n",
       "<!-- 28.concerned -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>28.concerned</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"832.2569\" cy=\"-450\" rx=\"57.4873\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"832.2569\" y=\"-445.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">28.concerned</text>\n",
       "</g>\n",
       "<!-- 27.linguistics&#45;&gt;28.concerned -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>27.linguistics&#45;&gt;28.concerned</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M832.2569,-503.8314C832.2569,-496.131 832.2569,-486.9743 832.2569,-478.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"835.757,-478.4132 832.2569,-468.4133 828.757,-478.4133 835.757,-478.4132\"/>\n",
       "</g>\n",
       "<!-- 31.interactions -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>31.interactions</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"832.2569\" cy=\"-378\" rx=\"62.3326\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"832.2569\" y=\"-373.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">31.interactions</text>\n",
       "</g>\n",
       "<!-- 28.concerned&#45;&gt;31.interactions -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>28.concerned&#45;&gt;31.interactions</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M832.2569,-431.8314C832.2569,-424.131 832.2569,-414.9743 832.2569,-406.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"835.757,-406.4132 832.2569,-396.4133 828.757,-406.4133 835.757,-406.4132\"/>\n",
       "</g>\n",
       "<!-- 29.with -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>29.with</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"745.2569\" cy=\"-306\" rx=\"36.7671\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"745.2569\" y=\"-301.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">29.with</text>\n",
       "</g>\n",
       "<!-- 31.interactions&#45;&gt;29.with -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>31.interactions&#45;&gt;29.with</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M811.6391,-360.937C799.8504,-351.1808 784.9273,-338.8307 772.2175,-328.3123\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"774.1757,-325.3897 764.2402,-321.7103 769.7127,-330.7824 774.1757,-325.3897\"/>\n",
       "</g>\n",
       "<!-- 30.the -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>30.the</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"832.2569\" cy=\"-306\" rx=\"31.9301\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"832.2569\" y=\"-301.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">30.the</text>\n",
       "</g>\n",
       "<!-- 31.interactions&#45;&gt;30.the -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>31.interactions&#45;&gt;30.the</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M832.2569,-359.8314C832.2569,-352.131 832.2569,-342.9743 832.2569,-334.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"835.757,-334.4132 832.2569,-324.4133 828.757,-334.4133 835.757,-334.4132\"/>\n",
       "</g>\n",
       "<!-- 33.computers -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>33.computers</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"940.2569\" cy=\"-306\" rx=\"57.9977\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"940.2569\" y=\"-301.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">33.computers</text>\n",
       "</g>\n",
       "<!-- 31.interactions&#45;&gt;33.computers -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>31.interactions&#45;&gt;33.computers</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M857.3057,-361.3008C872.1323,-351.4164 891.0931,-338.7759 907.1435,-328.0756\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"909.3372,-330.8196 915.7162,-322.3604 905.4542,-324.9953 909.3372,-330.8196\"/>\n",
       "</g>\n",
       "<!-- 32.between -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>32.between</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"837.2569\" cy=\"-234\" rx=\"50.7474\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"837.2569\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">32.between</text>\n",
       "</g>\n",
       "<!-- 33.computers&#45;&gt;32.between -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>33.computers&#45;&gt;32.between</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M916.6266,-289.4817C902.3946,-279.5332 884.0991,-266.7441 868.661,-255.9524\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"870.6236,-253.054 860.4222,-250.1933 866.613,-258.7912 870.6236,-253.054\"/>\n",
       "</g>\n",
       "<!-- 34.and -->\n",
       "<g id=\"node32\" class=\"node\">\n",
       "<title>34.and</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"940.2569\" cy=\"-234\" rx=\"33.8597\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"940.2569\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">34.and</text>\n",
       "</g>\n",
       "<!-- 33.computers&#45;&gt;34.and -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>33.computers&#45;&gt;34.and</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M940.2569,-287.8314C940.2569,-280.131 940.2569,-270.9743 940.2569,-262.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"943.757,-262.4132 940.2569,-252.4133 936.757,-262.4133 943.757,-262.4132\"/>\n",
       "</g>\n",
       "<!-- 39.languages -->\n",
       "<g id=\"node33\" class=\"node\">\n",
       "<title>39.languages</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1048.2569\" cy=\"-234\" rx=\"56.5441\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1048.2569\" y=\"-229.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">39.languages</text>\n",
       "</g>\n",
       "<!-- 33.computers&#45;&gt;39.languages -->\n",
       "<g id=\"edge36\" class=\"edge\">\n",
       "<title>33.computers&#45;&gt;39.languages</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M964.7637,-289.6621C979.6769,-279.72 998.9192,-266.8918 1015.1718,-256.0567\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1017.4679,-258.7325 1023.847,-250.2733 1013.585,-252.9081 1017.4679,-258.7325\"/>\n",
       "</g>\n",
       "<!-- 35.human -->\n",
       "<g id=\"node34\" class=\"node\">\n",
       "<title>35.human</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1048.2569\" cy=\"-162\" rx=\"45.4616\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1048.2569\" y=\"-157.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">35.human</text>\n",
       "</g>\n",
       "<!-- 39.languages&#45;&gt;35.human -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>39.languages&#45;&gt;35.human</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1048.2569,-215.8314C1048.2569,-208.131 1048.2569,-198.9743 1048.2569,-190.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1051.757,-190.4132 1048.2569,-180.4133 1044.757,-190.4133 1051.757,-190.4132\"/>\n",
       "</g>\n",
       "<!-- 37.natural -->\n",
       "<g id=\"node35\" class=\"node\">\n",
       "<title>37.natural</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1048.2569\" cy=\"-90\" rx=\"45.9287\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1048.2569\" y=\"-85.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">37.natural</text>\n",
       "</g>\n",
       "<!-- 35.human&#45;&gt;37.natural -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>35.human&#45;&gt;37.natural</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1048.2569,-143.8314C1048.2569,-136.131 1048.2569,-126.9743 1048.2569,-118.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1051.757,-118.4132 1048.2569,-108.4133 1044.757,-118.4133 1051.757,-118.4132\"/>\n",
       "</g>\n",
       "<!-- 36.&#45;LRB&#45; -->\n",
       "<g id=\"node36\" class=\"node\">\n",
       "<title>36.&#45;LRB&#45;</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"995.2569\" cy=\"-18\" rx=\"44.0015\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"995.2569\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">36.&#45;LRB&#45;</text>\n",
       "</g>\n",
       "<!-- 37.natural&#45;&gt;36.&#45;LRB&#45; -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>37.natural&#45;&gt;36.&#45;LRB&#45;</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1035.427,-72.5708C1028.982,-63.8153 1021.0515,-53.0418 1013.9443,-43.3867\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1016.7154,-41.2472 1007.9685,-35.2687 1011.0781,-45.3969 1016.7154,-41.2472\"/>\n",
       "</g>\n",
       "<!-- 38.&#45;RRB&#45; -->\n",
       "<g id=\"node37\" class=\"node\">\n",
       "<title>38.&#45;RRB&#45;</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"1102.2569\" cy=\"-18\" rx=\"44.9946\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1102.2569\" y=\"-13.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">38.&#45;RRB&#45;</text>\n",
       "</g>\n",
       "<!-- 37.natural&#45;&gt;38.&#45;RRB&#45; -->\n",
       "<g id=\"edge35\" class=\"edge\">\n",
       "<title>37.natural&#45;&gt;38.&#45;RRB&#45;</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1061.3288,-72.5708C1067.8954,-63.8153 1075.9755,-53.0418 1083.2169,-43.3867\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1086.1053,-45.3687 1089.3053,-35.2687 1080.5053,-41.1687 1086.1053,-45.3687\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x109f78518>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memo\n",
    "# more_itertools 、 nth\n",
    "# dot言語で:は行末を表す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 58. タプルの抽出\n",
    "Stanford Core NLPの係り受け解析の結果（collapsed-dependencies）に基づき，「主語 述語 目的語」の組をタブ区切り形式で出力せよ．ただし，主語，述語，目的語の定義は以下を参考にせよ．\n",
    "- 述語: nsubj関係とdobj関係の子（dependent）を持つ単語\n",
    "- 主語: 述語からnsubj関係にある子（dependent）\n",
    "- 目的語: 述語からdobj関係にある子（dependent）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "understanding\tinvolve\tgeneration\n",
      "Turing\tpublished\tarticle\n",
      "experiment\tinvolved\ttranslation\n",
      "ELIZA\tprovided\tinteraction\n",
      "patient\texceeded\tbase\n",
      "ELIZA\tprovide\tresponse\n",
      "which\tstructured\tinformation\n",
      "underpinnings\tdiscouraged\tsort\n",
      "that\tunderlies\tapproach\n",
      "Some\tproduced\tsystems\n",
      "which\tmake\tdecisions\n",
      "that\tcontains\terrors\n",
      "implementations\tinvolved\tcoding\n",
      "algorithms\ttake\tset\n",
      "Some\tproduced\tsystems\n",
      "which\tmake\tdecisions\n",
      "models\thave\tadvantage\n",
      "they\texpress\tcertainty\n",
      "Systems\thave\tadvantages\n",
      "procedures\tmake\tuse\n",
      "that\tmake\tdecisions\n"
     ]
    }
   ],
   "source": [
    "for deps in get_cd_deps(root):\n",
    "    nsubj_dic = {}\n",
    "    dobj_dic = {}\n",
    "    \n",
    "    for dep in deps:\n",
    "        dep_type = dep.get(\"type\")\n",
    "        gove_tpl = (dep.find(\"governor\").get(\"idx\"), dep.find(\"governor\").text)\n",
    "        depe_tpl = (dep.find(\"dependent\").get(\"idx\"), dep.find(\"dependent\").text)\n",
    "        \n",
    "        if dep_type == \"nsubj\":\n",
    "            nsubj_dic[gove_tpl] = depe_tpl\n",
    "        elif dep_type == \"dobj\":\n",
    "            dobj_dic[gove_tpl] = depe_tpl\n",
    "            \n",
    "    for key in nsubj_dic:\n",
    "        if key in dobj_dic:\n",
    "            print(nsubj_dic[key][1], key[1], dobj_dic[key][1], sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 59. S式の解析\n",
    "Stanford Core NLPの句構造解析の結果（S式）を読み込み，文中のすべての名詞句（NP）を表示せよ．入れ子になっている名詞句もすべて表示すること．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        <parse>(ROOT (S (PP (NP (JJ Natural) (NN language) (NN processing)) (IN From) (NP (NNP Wikipedia))) (, ,) (NP (NP (DT the) (JJ free) (NN encyclopedia) (JJ Natural) (NN language) (NN processing)) (PRN (-LRB- -LRB-) (NP (NN NLP)) (-RRB- -RRB-))) (VP (VBZ is) (NP (NP (NP (DT a) (NN field)) (PP (IN of) (NP (NN computer) (NN science)))) (, ,) (NP (JJ artificial) (NN intelligence)) (, ,) (CC and) (NP (NP (NNS linguistics)) (VP (VBN concerned) (PP (IN with) (NP (NP (DT the) (NNS interactions)) (PP (IN between) (NP (NP (NNS computers)) (CC and) (NP (JJ human) (-LRB- -LRB-) (JJ natural) (-RRB- -RRB-) (NNS languages)))))))))) (. .))) </parse>\n",
      "        <dependencies type=\"basic-dependencies\">\n",
      "grep: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!grep -A 2 'NP ' work/nlp.txt.xml | head -n 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz import sliding_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (NP .*)の内部だけ抜き出す\n",
    "def get_NP(parse):\n",
    "    is_NP = False\n",
    "    c = 0\n",
    "    for l, m, r in sliding_window(3, parse):\n",
    "        if l == '(' and m == 'N' and r == 'P' and is_NP == False:\n",
    "            is_NP = True\n",
    "            \n",
    "        if is_NP == True:          \n",
    "            yield l\n",
    "            \n",
    "            if l == '(':\n",
    "                c += 1\n",
    "            \n",
    "            elif l == ')':\n",
    "                c -= 1\n",
    "                \n",
    "            if c == 0:\n",
    "                yield '\\n'\n",
    "                is_NP = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------NPを取り出す(加工前)------\n",
      "(NP (JJ Natural) (NN language) (NN processing))\n",
      "(NP (NNP Wikipedia))\n",
      "(NP (NP (DT the) (JJ free) (NN encyclopedia) (JJ Natural) (NN language) (NN processing)) (PRN (-LRB- -LRB-) (NP (NN NLP)) (-RRB- -RRB-)))\n",
      "(NP (NP (NP (DT a) (NN field)) (PP (IN of) (NP (NN computer) (NN science)))) (, ,) (NP (JJ artificial) (NN intelligence)) (, ,) (CC and) (NP (NP (NNS linguistics)) (VP (VBN concerned) (PP (IN with) (NP (NP (DT the) (NNS interactions)) (PP (IN between) (NP (NP (NNS computers)) (CC and) (NP (JJ human) (-LRB- -LRB-) (JJ natural) (-RRB- -RRB-) (NNS languages)))))))))\n",
      "\n",
      "------加工後------\n",
      "Natural language processing\n",
      "Wikipedia\n",
      "the free encyclopedia Natural language processing NLP\n",
      "a field of computer science artificial intelligence and linguistics concerned with the interactions between computers and human natural languages\n"
     ]
    }
   ],
   "source": [
    "for parse in islice(root.iter(\"parse\"), 1):\n",
    "    lines = ''.join(get_NP(parse.text))\n",
    "    print('------NPを取り出す(加工前)------')\n",
    "    print(lines)\n",
    "    \n",
    "    print('------加工後------')\n",
    "    for line in lines.strip().split('\\n'):\n",
    "        print(' '.join(re.findall(r' (\\w*)\\)', line)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ↑これはミス。 問題文の意図と違う\n",
    "- 全通りのNPを表示しなければならない\n",
    "- 上記は全体のNPをとってきただけ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [S式 parser(nltk)](https://www.nltk.org/_modules/nltk/tokenize/sexpr.html)\n",
    "- [S式 parser(inforno)](http://inforno.net/articles/2008/09/19/sexp-library-for-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
